{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\nheart = pd.read_csv('https://extranet.who.int/tme/generateCSV.asp?ds=tbhivnonroutinesurv')\n\nheart.replace(NaN , 0 , inplace = True)",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "heart.head()",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>iso2</th>\n      <th>iso3</th>\n      <th>iso_numeric</th>\n      <th>g_whoregion</th>\n      <th>year</th>\n      <th>tbhiv_surv_prev</th>\n      <th>tbhiv_surv_yr</th>\n      <th>tbhiv_surv_cil</th>\n      <th>tbhiv_surv_ciu</th>\n      <th>tbhiv_sentin_prev</th>\n      <th>tbhiv_sentin_yr</th>\n      <th>tbhiv_sentin_cil</th>\n      <th>tbhiv_sentin_ciu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Algeria</td>\n      <td>DZ</td>\n      <td>DZA</td>\n      <td>12</td>\n      <td>AFR</td>\n      <td>2007</td>\n      <td>0.18</td>\n      <td>2002.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>American Samoa</td>\n      <td>AS</td>\n      <td>ASM</td>\n      <td>16</td>\n      <td>WPR</td>\n      <td>2008</td>\n      <td>100.00</td>\n      <td>2008.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Angola</td>\n      <td>AO</td>\n      <td>AGO</td>\n      <td>24</td>\n      <td>AFR</td>\n      <td>2009</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>2007.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Angola</td>\n      <td>AO</td>\n      <td>AGO</td>\n      <td>24</td>\n      <td>AFR</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>2011.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Anguilla</td>\n      <td>AI</td>\n      <td>AIA</td>\n      <td>660</td>\n      <td>AMR</td>\n      <td>2013</td>\n      <td>0.00</td>\n      <td>2013.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2013.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "          country iso2 iso3  iso_numeric g_whoregion  year  tbhiv_surv_prev  \\\n0         Algeria   DZ  DZA           12         AFR  2007             0.18   \n1  American Samoa   AS  ASM           16         WPR  2008           100.00   \n2          Angola   AO  AGO           24         AFR  2009              NaN   \n3          Angola   AO  AGO           24         AFR  2011              NaN   \n4        Anguilla   AI  AIA          660         AMR  2013             0.00   \n\n   tbhiv_surv_yr  tbhiv_surv_cil  tbhiv_surv_ciu  tbhiv_sentin_prev  \\\n0         2002.0             NaN             NaN                NaN   \n1         2008.0             NaN             NaN                NaN   \n2            NaN             NaN             NaN                9.0   \n3            NaN             NaN             NaN               14.0   \n4         2013.0             0.0             0.0                0.0   \n\n   tbhiv_sentin_yr  tbhiv_sentin_cil  tbhiv_sentin_ciu  \n0              NaN               NaN               NaN  \n1              NaN               NaN               NaN  \n2           2007.0               NaN               NaN  \n3           2011.0               NaN               NaN  \n4           2013.0               0.0               0.0  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\n\nlo = LogisticRegression()\n\ncols = ['year' , 'iso_numeric' , 'tbhiv_surv_prev' , 'tbhiv_surv_yr','tbhiv_surv_cil' , 'tbhiv_surv_ciu']\n\nX = heart[cols].dropna(how = 'any')\n\ny = heart['tbhiv_sentin_yr']\n\nX",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>iso_numeric</th>\n      <th>tbhiv_surv_prev</th>\n      <th>tbhiv_surv_yr</th>\n      <th>tbhiv_surv_cil</th>\n      <th>tbhiv_surv_ciu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>2013</td>\n      <td>660</td>\n      <td>0.00</td>\n      <td>2013.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2009</td>\n      <td>52</td>\n      <td>0.00</td>\n      <td>2008.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2008</td>\n      <td>112</td>\n      <td>3.00</td>\n      <td>2008.0</td>\n      <td>2.95</td>\n      <td>3.05</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2010</td>\n      <td>535</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2008</td>\n      <td>124</td>\n      <td>12.70</td>\n      <td>2007.0</td>\n      <td>11.10</td>\n      <td>14.30</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2009</td>\n      <td>124</td>\n      <td>5.00</td>\n      <td>2008.0</td>\n      <td>3.90</td>\n      <td>6.20</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2010</td>\n      <td>124</td>\n      <td>3.90</td>\n      <td>2009.0</td>\n      <td>3.00</td>\n      <td>4.90</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2010</td>\n      <td>136</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2008</td>\n      <td>344</td>\n      <td>0.51</td>\n      <td>2008.0</td>\n      <td>0.14</td>\n      <td>1.30</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2018</td>\n      <td>344</td>\n      <td>0.66</td>\n      <td>2018.0</td>\n      <td>0.41</td>\n      <td>1.05</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>2008</td>\n      <td>170</td>\n      <td>10.00</td>\n      <td>2008.0</td>\n      <td>9.00</td>\n      <td>11.00</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>2009</td>\n      <td>208</td>\n      <td>4.00</td>\n      <td>2009.0</td>\n      <td>2.00</td>\n      <td>8.00</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>2008</td>\n      <td>214</td>\n      <td>8.60</td>\n      <td>2005.0</td>\n      <td>6.40</td>\n      <td>11.20</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>2009</td>\n      <td>214</td>\n      <td>8.60</td>\n      <td>2005.0</td>\n      <td>7.00</td>\n      <td>11.90</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>2010</td>\n      <td>214</td>\n      <td>8.60</td>\n      <td>2005.0</td>\n      <td>7.00</td>\n      <td>11.90</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>2011</td>\n      <td>214</td>\n      <td>8.60</td>\n      <td>2005.0</td>\n      <td>7.00</td>\n      <td>11.90</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>2009</td>\n      <td>818</td>\n      <td>0.34</td>\n      <td>2009.0</td>\n      <td>0.10</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>2008</td>\n      <td>233</td>\n      <td>9.90</td>\n      <td>2008.0</td>\n      <td>7.12</td>\n      <td>12.68</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>2010</td>\n      <td>233</td>\n      <td>10.30</td>\n      <td>2010.0</td>\n      <td>7.12</td>\n      <td>12.68</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>2009</td>\n      <td>242</td>\n      <td>0.25</td>\n      <td>2009.0</td>\n      <td>0.10</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>2013</td>\n      <td>250</td>\n      <td>7.30</td>\n      <td>2012.0</td>\n      <td>6.10</td>\n      <td>8.70</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2010</td>\n      <td>258</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>2017</td>\n      <td>360</td>\n      <td>2.41</td>\n      <td>2017.0</td>\n      <td>1.27</td>\n      <td>4.53</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>2010</td>\n      <td>376</td>\n      <td>3.80</td>\n      <td>2010.0</td>\n      <td>3.61</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>2008</td>\n      <td>400</td>\n      <td>0.00</td>\n      <td>2008.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>2009</td>\n      <td>400</td>\n      <td>0.00</td>\n      <td>2009.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>2010</td>\n      <td>400</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>2008</td>\n      <td>404</td>\n      <td>45.00</td>\n      <td>2008.0</td>\n      <td>42.00</td>\n      <td>48.00</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>2009</td>\n      <td>404</td>\n      <td>44.00</td>\n      <td>2009.0</td>\n      <td>42.00</td>\n      <td>46.00</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>2010</td>\n      <td>404</td>\n      <td>41.00</td>\n      <td>2010.0</td>\n      <td>37.00</td>\n      <td>45.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>2009</td>\n      <td>562</td>\n      <td>11.00</td>\n      <td>2009.0</td>\n      <td>9.00</td>\n      <td>13.00</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>2010</td>\n      <td>562</td>\n      <td>11.00</td>\n      <td>2009.0</td>\n      <td>9.00</td>\n      <td>13.00</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>2017</td>\n      <td>570</td>\n      <td>0.00</td>\n      <td>2017.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>2008</td>\n      <td>580</td>\n      <td>0.00</td>\n      <td>2008.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>2009</td>\n      <td>580</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>2010</td>\n      <td>580</td>\n      <td>0.00</td>\n      <td>2011.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>2008</td>\n      <td>512</td>\n      <td>2.27</td>\n      <td>2008.0</td>\n      <td>0.72</td>\n      <td>3.83</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>2009</td>\n      <td>512</td>\n      <td>0.90</td>\n      <td>2009.0</td>\n      <td>0.18</td>\n      <td>2.70</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>2010</td>\n      <td>512</td>\n      <td>1.27</td>\n      <td>2010.0</td>\n      <td>0.03</td>\n      <td>2.51</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>2010</td>\n      <td>600</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>2008</td>\n      <td>620</td>\n      <td>14.60</td>\n      <td>2008.0</td>\n      <td>13.38</td>\n      <td>15.94</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>2010</td>\n      <td>620</td>\n      <td>12.00</td>\n      <td>2010.0</td>\n      <td>10.00</td>\n      <td>13.00</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>2008</td>\n      <td>634</td>\n      <td>0.01</td>\n      <td>2009.0</td>\n      <td>0.00</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>2009</td>\n      <td>634</td>\n      <td>0.20</td>\n      <td>2009.0</td>\n      <td>0.10</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>2011</td>\n      <td>634</td>\n      <td>0.20</td>\n      <td>2011.0</td>\n      <td>0.10</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <td>2008</td>\n      <td>643</td>\n      <td>6.00</td>\n      <td>2008.0</td>\n      <td>1.00</td>\n      <td>3.00</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>2009</td>\n      <td>643</td>\n      <td>8.00</td>\n      <td>2009.0</td>\n      <td>7.00</td>\n      <td>9.00</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>2011</td>\n      <td>688</td>\n      <td>0.30</td>\n      <td>2011.0</td>\n      <td>0.29</td>\n      <td>0.41</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>2009</td>\n      <td>690</td>\n      <td>0.00</td>\n      <td>2009.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>233</th>\n      <td>2010</td>\n      <td>706</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>2012</td>\n      <td>706</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>2011</td>\n      <td>728</td>\n      <td>14.70</td>\n      <td>2011.0</td>\n      <td>1.80</td>\n      <td>18.10</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>2011</td>\n      <td>144</td>\n      <td>0.07</td>\n      <td>2011.0</td>\n      <td>0.00</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>2008</td>\n      <td>762</td>\n      <td>4.00</td>\n      <td>2008.0</td>\n      <td>13.00</td>\n      <td>18.00</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>2009</td>\n      <td>776</td>\n      <td>0.00</td>\n      <td>2009.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>2010</td>\n      <td>776</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>2009</td>\n      <td>780</td>\n      <td>0.00</td>\n      <td>2009.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>2010</td>\n      <td>780</td>\n      <td>0.00</td>\n      <td>2010.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>2009</td>\n      <td>858</td>\n      <td>16.40</td>\n      <td>2009.0</td>\n      <td>13.56</td>\n      <td>19.18</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>2008</td>\n      <td>275</td>\n      <td>0.00</td>\n      <td>2008.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>78 rows Ã— 6 columns</p>\n</div>",
            "text/plain": "     year  iso_numeric  tbhiv_surv_prev  tbhiv_surv_yr  tbhiv_surv_cil  \\\n4    2013          660             0.00         2013.0            0.00   \n11   2009           52             0.00         2008.0            0.00   \n12   2008          112             3.00         2008.0            2.95   \n16   2010          535             0.00         2010.0            0.00   \n24   2008          124            12.70         2007.0           11.10   \n25   2009          124             5.00         2008.0            3.90   \n26   2010          124             3.90         2009.0            3.00   \n28   2010          136             0.00         2010.0            0.00   \n32   2008          344             0.51         2008.0            0.14   \n39   2018          344             0.66         2018.0            0.41   \n41   2008          170            10.00         2008.0            9.00   \n50   2009          208             4.00         2009.0            2.00   \n57   2008          214             8.60         2005.0            6.40   \n58   2009          214             8.60         2005.0            7.00   \n59   2010          214             8.60         2005.0            7.00   \n60   2011          214             8.60         2005.0            7.00   \n68   2009          818             0.34         2009.0            0.10   \n73   2008          233             9.90         2008.0            7.12   \n75   2010          233            10.30         2010.0            7.12   \n80   2009          242             0.25         2009.0            0.10   \n85   2013          250             7.30         2012.0            6.10   \n91   2010          258             0.00         2010.0            0.00   \n111  2017          360             2.41         2017.0            1.27   \n113  2010          376             3.80         2010.0            3.61   \n116  2008          400             0.00         2008.0            0.00   \n117  2009          400             0.00         2009.0            0.00   \n118  2010          400             0.00         2010.0            0.00   \n121  2008          404            45.00         2008.0           42.00   \n122  2009          404            44.00         2009.0           42.00   \n123  2010          404            41.00         2010.0           37.00   \n..    ...          ...              ...            ...             ...   \n196  2009          562            11.00         2009.0            9.00   \n197  2010          562            11.00         2009.0            9.00   \n198  2017          570             0.00         2017.0            0.00   \n201  2008          580             0.00         2008.0            0.00   \n202  2009          580             0.00         2010.0            0.00   \n203  2010          580             0.00         2011.0            0.00   \n204  2008          512             2.27         2008.0            0.72   \n205  2009          512             0.90         2009.0            0.18   \n206  2010          512             1.27         2010.0            0.03   \n214  2010          600             0.00         2010.0            0.00   \n217  2008          620            14.60         2008.0           13.38   \n218  2010          620            12.00         2010.0           10.00   \n219  2008          634             0.01         2009.0            0.00   \n220  2009          634             0.20         2009.0            0.10   \n221  2011          634             0.20         2011.0            0.10   \n224  2008          643             6.00         2008.0            1.00   \n225  2009          643             8.00         2009.0            7.00   \n227  2011          688             0.30         2011.0            0.29   \n229  2009          690             0.00         2009.0            0.00   \n233  2010          706             0.00         2010.0            0.00   \n234  2012          706             0.00         2010.0            0.00   \n236  2011          728            14.70         2011.0            1.80   \n239  2011          144             0.07         2011.0            0.00   \n242  2008          762             4.00         2008.0           13.00   \n251  2009          776             0.00         2009.0            0.00   \n252  2010          776             0.00         2010.0            0.00   \n255  2009          780             0.00         2009.0            0.00   \n256  2010          780             0.00         2010.0            0.00   \n264  2009          858            16.40         2009.0           13.56   \n269  2008          275             0.00         2008.0            0.00   \n\n     tbhiv_surv_ciu  \n4              0.00  \n11             0.00  \n12             3.05  \n16             0.00  \n24            14.30  \n25             6.20  \n26             4.90  \n28             0.00  \n32             1.30  \n39             1.05  \n41            11.00  \n50             8.00  \n57            11.20  \n58            11.90  \n59            11.90  \n60            11.90  \n68             0.50  \n73            12.68  \n75            12.68  \n80             0.50  \n85             8.70  \n91             0.00  \n111            4.53  \n113            4.00  \n116            0.00  \n117            0.00  \n118            0.00  \n121           48.00  \n122           46.00  \n123           45.00  \n..              ...  \n196           13.00  \n197           13.00  \n198            0.00  \n201            0.00  \n202            0.00  \n203            0.00  \n204            3.83  \n205            2.70  \n206            2.51  \n214            0.00  \n217           15.94  \n218           13.00  \n219            0.05  \n220            0.40  \n221            0.40  \n224            3.00  \n225            9.00  \n227            0.41  \n229            0.00  \n233            0.00  \n234            0.00  \n236           18.10  \n239            0.35  \n242           18.00  \n251            0.00  \n252            0.00  \n255            0.00  \n256            0.00  \n264           19.18  \n269            0.00  \n\n[78 rows x 6 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nx_train , x_test , y_train , y_test = train_test_split(X , y , test_size = 0.3)",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [78, 272]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-7cd9b424fbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [78, 272]"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "lo.fit(x_train , y_train)",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d9b6e5390eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1288\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}